{"cells":[{"cell_type":"markdown","metadata":{},"source":["<img src=\"https://github.com/FarzadNekouee/Traffic-Violation-Detection/blob/master/image.png?raw=true\" width=\"1800\">"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border-radius:10px; padding: 15px; background-color: #a3b8c7; font-size:120%; text-align:left\">\n","\n","<h2 align=\"left\"><font color=#10191f>Problem:</font></h2>\n","\n","In urban intersections, there's a critical need for an automatic system that detects red-light running violations through real-time CCTV footage, ensuring violators are identified and fined. While deep learning approaches are often lauded, resource constraints in our scenario necessitated a pivot to classical digital image processing techniques. Despite implementing our solution on an offline video taken under the challenging conditions of nighttime, we still witness the astonishing capabilities of traditional image processing techniques in action.   "]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border-radius:10px; padding: 15px; background-color: #a3b8c7; font-size:120%; text-align:left\">\n","\n","<h2 align=\"left\"><font color=#10191f>System Features: </font></h2>\n","\n","    \n","- Non-Deep Learning Real-Time Traffic Light Color Recognition\n","    \n","    \n","- Adaptive and Stable Digital Image Processing Technique for Night-Time Stop Line Detection and Color-Correlation to Traffic Light Status\n","    \n","    \n","- Robust License Plate Extraction from Night-Time Traffic Frames using Digital Image Processing Techniques\n","    \n","    \n","- Text Recognition on License Plates with PyTesseract OCR\n","    \n","    \n","- Displaying Penalized License Plates on Video Frames with Dynamic Positioning\n","    \n","    \n","- Database Integration for Recording Fined License Plate Violations using MySQL"]},{"cell_type":"markdown","metadata":{},"source":["<h2 align=\"left\"><font color=#10191f>Demo:</font></h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-08-16T20:01:57.599226Z","iopub.status.busy":"2023-08-16T20:01:57.598002Z","iopub.status.idle":"2023-08-16T20:01:57.634523Z","shell.execute_reply":"2023-08-16T20:01:57.633334Z","shell.execute_reply.started":"2023-08-16T20:01:57.599179Z"},"trusted":true},"outputs":[],"source":["from IPython.display import display, HTML\n","\n","# Youtube\n","YouTubeVideo_ID = 'dzHYjDuRYzs'\n","\n","# Adjust the width and height values\n","width = 1280  \n","height = 720  \n","\n","# create a HTML string to center the video\n","html_str = \"\"\"\n","<div style=\"display: flex; justify-content: center;\">\n","    <iframe width=\"{}\" height=\"{}\" src=\"https://www.youtube.com/embed/{}\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n","</div>\n","\"\"\".format(width, height, YouTubeVideo_ID)\n","\n","# Display HTML\n","display(HTML(html_str))\n"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"contents_tabel\"></a>    \n","<div style=\"border-radius:10px; padding: 15px; background-color: #a3b8c7; font-size:120%; text-align:left\">\n","\n","<h2 align=\"left\"><font color=#10191f>Table of Contents: </font></h2>\n","    \n","* <a href=\"#step1\" style=\"color: #10191f; text-decoration: none;\">Step 1 | Import Necessary Libraries</a>\n","* <a href=\"#step2\" style=\"color: #10191f; text-decoration: none;\">Step 2 | Real-Time Traffic Light Color Recognition</a>\n","* <a href=\"#step3\" style=\"color: #10191f; text-decoration: none;\">Step 3 | Adaptive Stop Line Detection</a>\n","* <a href=\"#step4\" style=\"color: #10191f; text-decoration: none;\">Step 4 | Robust License Plate Extraction</a>\n","* <a href=\"#step5\" style=\"color: #10191f; text-decoration: none;\">Step 5 | Text Recognition on License Plates</a>\n","* <a href=\"#step6\" style=\"color: #10191f; text-decoration: none;\">Step 6 | Display Penalized License Plates</a>\n","* <a href=\"#step7\" style=\"color: #10191f; text-decoration: none;\">Step 7 | Log Fined License Plates into MySQL</a>\n","* <a href=\"#step8\" style=\"color: #10191f; text-decoration: none;\">Step 8 | Traffic Violation Monitoring Execution</a>\n"]},{"cell_type":"markdown","metadata":{},"source":["<h2 align=\"left\"><font color=#10191f>Let's get started:</font></h2>"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"step1\"></a>\n","# <p style=\"background-color:#10191f; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 1 | Import Necessary Libraries</p>\n","\n","‚¨ÜÔ∏è [Tabel of Contents](#contents_tabel)"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border-radius:10px; padding: 15px; background-color: #a3b8c7; font-size:115%; text-align:left\">\n","   \n","First of all, let's import essential libraries for our image processing, text recognition, and database connectivity tasks:"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-08-16T20:01:57.677285Z","iopub.status.busy":"2023-08-16T20:01:57.675886Z","iopub.status.idle":"2023-08-16T20:02:28.621683Z","shell.execute_reply":"2023-08-16T20:02:28.620656Z","shell.execute_reply.started":"2023-08-16T20:01:57.677237Z"},"trusted":true},"outputs":[],"source":["!pip install mysql-connector-python"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-08-16T20:02:28.624192Z","iopub.status.busy":"2023-08-16T20:02:28.623828Z","iopub.status.idle":"2023-08-16T20:02:32.922563Z","shell.execute_reply":"2023-08-16T20:02:32.921383Z","shell.execute_reply.started":"2023-08-16T20:02:28.624154Z"},"trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","import os\n","import requests\n","import pytesseract\n","import easyocr\n","import re\n","import mysql.connector\n","import pytesseract\n","from PIL import Image\n","from collections import deque\n","from mysql.connector import Error"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border-radius:10px; padding: 15px; background-color: #a3b8c7; font-size:115%; text-align:left\">\n","\n","Afterward, let's define our database connection parameters."]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border-radius:10px; padding: 15px; background-color: #a3b8c7; font-size:115%; text-align:left\">\n","<h2 align=\"left\"><font color=#10191f>üîî Instruction:</font></h2>\n","    \n","To successfully execute the subsequent sections, kindly  replace the placeholders for `your_username` and `your_password` with your own database username and password, respectively."]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-08-16T20:02:32.925368Z","iopub.status.busy":"2023-08-16T20:02:32.92397Z","iopub.status.idle":"2023-08-16T20:02:32.932729Z","shell.execute_reply":"2023-08-16T20:02:32.930246Z","shell.execute_reply.started":"2023-08-16T20:02:32.925334Z"},"trusted":true},"outputs":[],"source":["# Database Connection Constants\n","DB_HOST = 'localhost'\n","DB_USER = 'root'\n","DB_PASSWORD = ''\n","DB_NAME = 'traffic_violations_db'"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"step2\"></a>\n","# <p style=\"background-color:#10191f; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 2 |  Real-Time Traffic Light Color Recognition</p>\n","\n","‚¨ÜÔ∏è [Tabel of Contents](#contents_tabel)"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border-radius:10px; padding: 15px; background-color: #a3b8c7; font-size:115%; text-align:left\">\n","\n","In this section, my aim is to detect the color of a traffic light in real-time from a given frame. Here's a breakdown of the steps involved:\n","\n","__1. Region of Interest (ROI)__: We begin by defining a region of interest in the image. This is where we expect our traffic light to be, and we isolate this portion from the rest to focus our analysis on it.\n","\n","__2. HSV Conversion__: The ROI is then converted from the RGB color space to __HSV__ (Hue, Saturation, Value). HSV is often better for color-based operations since it separates the chromatic content (hue) from the luminance content.\n","\n","__3. Color Range Definition__: We define the range of hue values corresponding to red and yellow colors. These values are essential to detect if the traffic light is showing red, yellow, or green.\n","\n","__4. Color Masks__: Using the previously defined ranges, masks (binary images) are created that highlight regions in the ROI where red and yellow colors are detected.\n","\n","__5. Color Recognition__: We then examine the masks. If there are any non-zero values in the red mask, we deduce the light is red. If there are non-zero values in the yellow mask, the light is yellow. If neither red nor yellow is detected, we conclude the light is green.\n","\n","__6. Overlay Information__: Finally, we overlay a textual message on the main image indicating the detected traffic light status. This will visually inform if the signal indicates \"Stop\", \"Caution\", or \"Go\".\n","\n","____\n","    \n","`detect_traffic_light_color` function enables us to automatically detect and indicate the color of traffic lights in real-time, providing vital information for further processing, especially in red-light violation detection.\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-08-16T20:02:32.93503Z","iopub.status.busy":"2023-08-16T20:02:32.934696Z","iopub.status.idle":"2023-08-16T20:02:32.955064Z","shell.execute_reply":"2023-08-16T20:02:32.954236Z","shell.execute_reply.started":"2023-08-16T20:02:32.935002Z"},"trusted":true},"outputs":[],"source":["def detect_traffic_light_color(image, rect):\n","    # Extract rectangle dimensions\n","    x, y, w, h = rect\n","    # Extract region of interest (ROI) from the image based on the rectangle\n","    roi = image[y:y+h, x:x+w]\n","    \n","    # Convert ROI to HSV color space\n","    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n","\n","    # Define HSV range for red color\n","    red_lower = np.array([0, 120, 70])\n","    red_upper = np.array([10, 255, 255])\n","    \n","    # Define HSV range for yellow color\n","    yellow_lower = np.array([20, 100, 100])\n","    yellow_upper = np.array([30, 255, 255])\n","\n","    # Create binary masks for detecting red and yellow in the ROI\n","    red_mask = cv2.inRange(hsv, red_lower, red_upper)\n","    yellow_mask = cv2.inRange(hsv, yellow_lower, yellow_upper)\n","    \n","    # Font details for overlaying text on the image\n","    font = cv2.FONT_HERSHEY_TRIPLEX\n","    font_scale = 1  \n","    font_thickness = 2  \n","    \n","    # Check which color is present based on the masks\n","    if cv2.countNonZero(red_mask) > 0:\n","        text_color = (0, 0, 255)\n","        message = \"Detected Signal Status: Stop\"\n","        color = 'red'\n","    elif cv2.countNonZero(yellow_mask) > 0:\n","        text_color = (0, 255, 255)\n","        message = \"Detected Signal Status: Caution\"\n","        color = 'yellow'\n","    else:\n","        text_color = (0, 255, 0)\n","        message = \"Detected Signal Status: Go\"\n","        color = 'green'\n","        \n","    # Overlay the detected traffic light status on the main image\n","    cv2.putText(image, message, (15, 70), font, font_scale+0.5, text_color, font_thickness+1, cv2.LINE_AA)\n","    # Add a separator line\n","    cv2.putText(image, 34*'-', (10, 115), font, font_scale, (255,255,255), font_thickness, cv2.LINE_AA)\n","    \n","    # Return the modified image and detected color\n","    return image, color"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"step3\"></a>\n","# <p style=\"background-color:#10191f; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 3 |  Adaptive Stop Line Detection</p>\n","\n","‚¨ÜÔ∏è [Tabel of Contents](#contents_tabel)"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border-radius:10px; padding: 15px; background-color: #a3b8c7; font-size:115%; text-align:left\"> \n","    \n","I am going to define a class in this part. My primary objective with the `LineDetector` class is to detect the stop line in the video frames. Once identified, we then aim to visually highlight the line, according to the detected traffic light status (red, yellow, or green).\n","    \n","Due to the natural phenomenon of line jittering and fluctuations across video frames, it's crucial to maintain a stable representation. This is where the concept of __queues__, particularly deque, comes into play. By using a deque, we can keep track of the line's positions over a set number of previous frames, helping to smoothen out abrupt changes and ensuring a more consistent visual representation.\n","\n","The choice of implementing this logic within a class instead of a standalone function was essential. This decision ensures that our queues, which store the y-coordinates of the detected line's starting and ending points, persist across frames. If we had opted for a simple function, each function call would re-initialize these queues, leading to inconsistencies in line detection across frames.\n","    \n","Here's a look at its operations:\n","\n","__1. Initialization__: The class starts with two queues (`y_start_queue` and `y_end_queue`) that store y-coordinates of the stop line's start and end points across frames, leading to a smoother depiction.\n","\n","__2. Color Code Mapping__: A nested function, `get_color_code`, associates color names (red, green, yellow) with their BGR counterparts. This mapping is used to dynamically highlight the detected stop line with red, yellow, or green based on the traffic light's color, achieved by adjusting the corresponding channel color of the detected line on the original frame.\n","\n","__3. Line Equations__: Based on provided slope and intercept values, three line equations are formulated to focus on the segment of interest.\n","\n","__4. Creating Masks__: Starting with the line equations, multiple masks are generated to narrow down the area of interest. Eventually, these are combined to produce one final mask that spotlights the stop line while minimizing distractions from other elements in the frame.\n","\n","__5. Image Processing__: The refined mask undergoes transformations, including grayscale conversion, blurring, histogram equalization, and edge detection.\n","\n","__6. Hough Line Transform__: Using this critical step, the __Hough Line Transform__ is applied to detect the stop line based on the identified edges within the processed image. The parameters of the detected stop line are then accumulated in our queues.\n","\n","__7. Line Drawing & Coloring__: The detected line, derived from prior step, is sketched on the original frame. The traffic light's color determines its hue, altering the original frame's channels.\n","\n","__8. Final Mask Creation__: To conclude, a final mask is generated, turning pixels above the detected line to black. This mask serves as the second output of our method and plays a pivotal role in subsequent steps, particularly in isolating license plates of cars positioned below the line‚Äîeffectively targeting vehicles that have crossed the stop line during a red light signal.\n","    \n","____\n","    \n","`LineDetector` class stands as a cornerstone for traffic and road-based computer vision tasks, adeptly detecting and visualizing specific lines in frames.\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-08-16T20:02:32.959524Z","iopub.status.busy":"2023-08-16T20:02:32.958858Z","iopub.status.idle":"2023-08-16T20:02:32.988166Z","shell.execute_reply":"2023-08-16T20:02:32.986822Z","shell.execute_reply.started":"2023-08-16T20:02:32.959488Z"},"trusted":true},"outputs":[],"source":["class LineDetector:\n","    def __init__(self, num_frames_avg=10):\n","        # Initialize two deque queues to hold y-coordinate values across frames\n","        self.y_start_queue = deque(maxlen=num_frames_avg)\n","        self.y_end_queue = deque(maxlen=num_frames_avg)\n","\n","    \n","    def detect_white_line(self, frame, color, \n","                          slope1=0.03, intercept1=920, slope2=0.03, intercept2=770, slope3=-0.8, intercept3=2420):\n","        \n","        # Function to map color names to BGR values\n","        def get_color_code(color_name):\n","            color_codes = {\n","                'red': (0, 0, 255),\n","                'green': (0, 255, 0),\n","                'yellow': (0, 255, 255)\n","                 }\n","            return color_codes.get(color_name.lower())\n","\n","        frame_org = frame.copy()\n","        \n","        # Line equations for defining region of interest (ROI)\n","        def line1(x): return slope1 * x + intercept1\n","        def line2(x): return slope2 * x + intercept2\n","        def line3(x): return slope3 * x + intercept3\n","\n","        height, width, _ = frame.shape\n","        \n","        # Create a mask to spotlight the line's desired area\n","        mask1 = frame.copy()\n","        # Set pixels below the first line to black in mask1\n","        for x in range(width):\n","            y_line = line1(x)\n","            mask1[int(y_line):, x] = 0\n","\n","        mask2 = mask1.copy()\n","        # Set pixels above the second line to black in mask2\n","        for x in range(width):\n","            y_line = line2(x)\n","            mask2[:int(y_line), x] = 0\n","\n","        mask3 = mask2.copy()\n","        # Set pixels to the left of the third line to black in mask3 (final mask)\n","        for y in range(height):\n","            x_line = line3(y)\n","            mask3[y, :int(x_line)] = 0\n","\n","        # Convert the mask to grayscale\n","        gray = cv2.cvtColor(mask3, cv2.COLOR_BGR2GRAY)\n","\n","        # Apply a Gaussian filter to the ROI\n","        blurred_gray = cv2.GaussianBlur(gray, (7, 7), 0)\n","\n","        # Apply CLAHE to equalize the histogram\n","        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n","        gray_clahe = clahe.apply(blurred_gray)\n","\n","        # Perform edge detection\n","        edges = cv2.Canny(gray, 30, 100)\n","\n","        # Perform a dilation and erosion to close gaps in between object edges\n","        dilated_edges = cv2.dilate(edges, None, iterations=1)\n","        edges = cv2.erode(dilated_edges, None, iterations=1)\n","\n","        # Perform Hough Line Transform\n","        lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=160, maxLineGap=5)\n","\n","        # Calculate x coordinates for the start and end of the line\n","        x_start = 0\n","        x_end = width - 1\n","\n","        if lines is not None:\n","            for line in lines:\n","                x1, y1, x2, y2 = line[0]\n","\n","                # Calculate line parameters\n","                slope = (y2 - y1) / (x2 - x1 + np.finfo(float).eps)  # Add a small number to avoid division by zero\n","                intercept = y1 - slope * x1\n","\n","                # Calculate corresponding y coordinates\n","                y_start = int(slope * x_start + intercept)\n","                y_end = int(slope * x_end + intercept)\n","\n","                # Add the y_start and y_end values to the queues\n","                self.y_start_queue.append(y_start)\n","                self.y_end_queue.append(y_end)\n","\n","        # Compute the average y_start and y_end values\n","        avg_y_start = int(sum(self.y_start_queue) / len(self.y_start_queue)) if self.y_start_queue else 0\n","        avg_y_end = int(sum(self.y_end_queue) / len(self.y_end_queue)) if self.y_end_queue else 0\n","\n","        \n","        # Draw the line\n","        line_start_ratio=0.32\n","        x_start_adj = x_start + int(line_start_ratio * (x_end - x_start))  # Adjusted x_start\n","        avg_y_start_adj = avg_y_start + int(line_start_ratio * (avg_y_end - avg_y_start))  # Adjusted avg_y_start\n","\n","        # Create a mask with the same size as the frame and all zeros (black)\n","        mask = np.zeros_like(frame)\n","\n","        # Draw the line on the mask\n","        cv2.line(mask, (x_start_adj, avg_y_start_adj), (x_end, avg_y_end), (255, 255, 255), 4)\n","\n","        # Determine which color channel(s) to change based on the color argument\n","        color_code = get_color_code(color)\n","        if color_code == (0, 255, 0):  # Green\n","            channel_indices = [1]\n","        elif color_code == (0, 0, 255):  # Red\n","            channel_indices = [2]\n","        elif color_code == (0, 255, 255):  # Yellow\n","            # Yellow in BGR is a combination of green and red channels.\n","            # Here we modify both green and red channels.\n","            channel_indices = [1, 2]\n","        else:\n","            raise ValueError('Unsupported color')\n","\n","        # Change the specified color channels of the frame where the mask is white\n","        for channel_index in channel_indices:\n","            frame[mask[:,:,channel_index] == 255, channel_index] = 255\n","                \n","                \n","        # Calculate slope and intercept for the average green line\n","        slope_avg = (avg_y_end - avg_y_start) / (x_end - x_start + np.finfo(float).eps)\n","        intercept_avg = avg_y_start - slope_avg * x_start\n","\n","        # Create a mask with the pixels above the green line set to black\n","        mask_line = np.copy(frame_org)\n","        for x in range(width):\n","            y_line = slope_avg * x + intercept_avg - 35\n","            mask_line[:int(y_line), x] = 0  # set pixels above the line to black\n","\n","        return frame, mask_line"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"step4\"></a>\n","# <p style=\"background-color:#10191f; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 4 |  Robust License Plate Extraction</p>\n","\n","‚¨ÜÔ∏è [Tabel of Contents](#contents_tabel)"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border-radius:10px; padding: 15px; background-color: #a3b8c7; font-size:115%; text-align:left\">   \n","    \n","In this step, I am going to define another function. The function `extract_license_plate` is structured into several key phases to detect and extract license plates from a given frame. Here's an outline of the process:\n","\n","__1. Preprocessing__: The code initiates with essential preprocessing steps. This includes converting the image to grayscale to work with single-channel intensity values and applying __CLAHE__ to equalize the histogram, thereby enhancing the image contrast. Additionally, noise is minimized using erosion, paving the way for more accurate detection.\n","\n","__2. Isolating and Cropping the Region of Interest (ROI)__: Working on a mask from the previous steps, where pixels above the stop line are colored black, the code identifies the non-black pixels indicating the road below the stop line. It computes a bounding box around this region and then crops it, also slightly excluding a portion on the left side which belongs to the opposite lane. This focused cropped region becomes the prime ROI for the license plate detection, as __Haar cascade classifier__ performs more efficiently on smaller, well-defined ROIs.\n","\n","__3. Haar Cascade Classifier__: The cropped grayscale image is then passed to a Haar cascade classifier, a classic non-deep learning method adept at pattern recognition. This classifier has been pre-trained to recognize license plate patterns, and it returns the locations of potential license plates in the form of rectangles.\n","\n","__4. Extracting License Plates & Final Output__: The detected license plates are marked with rectangles on the original frame. Additionally, the potential license plates are cropped from the grayscale region and stored in a list. The function concludes by returning both the original frame with license plates bounded and the potential detected license plates.\n","\n","___\n","    \n","`extract_license_plate` is a streamlined and well-organized function that is key for applications requiring license plate recognition. It leverages classic computer vision techniques to efficiently extract the valuable information required.\n"," "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-08-16T20:02:32.99053Z","iopub.status.busy":"2023-08-16T20:02:32.989967Z","iopub.status.idle":"2023-08-16T20:02:33.005508Z","shell.execute_reply":"2023-08-16T20:02:33.004473Z","shell.execute_reply.started":"2023-08-16T20:02:32.990489Z"},"trusted":true},"outputs":[],"source":["def extract_license_plate(frame, mask_line):    \n","    # Convert the image to grayscale (Haar cascades are typically trained on grayscale images)\n","    gray = cv2.cvtColor(mask_line, cv2.COLOR_BGR2GRAY)\n","    \n","    # Apply CLAHE to equalize the histogram\n","    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n","    gray = clahe.apply(gray)\n","    \n","    # Erode the image using a 2x2 kernel to remove noise\n","    kernel = np.ones((2, 2), np.uint8)\n","    gray = cv2.erode(gray, kernel, iterations=1)\n","\n","    # Find the bounding box of non-black pixels\n","    non_black_points = cv2.findNonZero(gray)\n","    x, y, w, h = cv2.boundingRect(non_black_points)\n","\n","    # Calculate the new width of the bounding box, excluding 30% on the right side\n","    w = int(w * 0.7)\n","\n","    # Crop the image to the bounding box\n","    cropped_gray = gray[y:y+h, x:x+w]\n","\n","    # Detect license plates in the image (this returns a list of rectangles)\n","    license_plates = license_plate_cascade.detectMultiScale(cropped_gray, scaleFactor=1.07, minNeighbors=15, minSize=(20, 20))\n","\n","    # List to hold cropped license plate images\n","    license_plate_images = []\n","\n","    # Loop over the license plates\n","    for (x_plate, y_plate, w_plate, h_plate) in license_plates:\n","        # Draw a rectangle around the license plate in the original frame (here you need the original coordinates)\n","        cv2.rectangle(frame, (x_plate + x, y_plate + y), (x_plate + x + w_plate, y_plate + y + h_plate), (0, 255, 0), 3)\n","    \n","        # Crop the license plate and append it to the list (here x_plate and y_plate are relative to cropped_gray)\n","        license_plate_image = cropped_gray[y_plate:y_plate+h_plate, x_plate:x_plate+w_plate]\n","        license_plate_images.append(license_plate_image)\n","\n","    return frame, license_plate_images"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"step5\"></a>\n","# <p style=\"background-color:#10191f; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 5 | Text Recognition on License Plates</p>\n","\n","‚¨ÜÔ∏è [Tabel of Contents](#contents_tabel)"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border-radius:10px; padding: 15px; background-color: #a3b8c7; font-size:115%; text-align:left\"> \n","    \n","I am going to define `apply_ocr_to_image` function, which is meticulously crafted to recognize and extract textual information (like numbers and characters) from given license plate images using the `PyTesseract OCR`. Here's a concise breakdown of its operations:\n","\n","__1. Image Thresholding__: The image is thresholded, converting it into a binary format. This aids in distinguishing characters from the background, ensuring the text on the license plate is in black and the background is white.\n","\n","__2. Format Conversion__: As PyTesseract requires the PIL Image format, the thresholded image, which is initially in OpenCV's format, is seamlessly converted to the PIL Image format to make it compatible with the OCR process.\n","\n","__3. Text Extraction using Classic OCR__: The PyTesseract OCR tool is then used to extract text from the converted image. A special configuration (`--psm 6`) is employed to aid the OCR in recognizing sparse text on a sparse background, typical for license plates.\n","\n","__4. Text Cleanup__: Post extraction, any extraneous white spaces that might have been appended to the start or end of the recognized text are removed to ensure the returned text is clean and compact.\n","\n","____\n","    \n","With `apply_ocr_to_image` function in hand, applications can efficiently extract textual information from license plate images, leveraging the power of traditional machine learning techniques for OCR.\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-08-16T20:02:33.007983Z","iopub.status.busy":"2023-08-16T20:02:33.006998Z","iopub.status.idle":"2023-08-16T20:02:33.0223Z","shell.execute_reply":"2023-08-16T20:02:33.021018Z","shell.execute_reply.started":"2023-08-16T20:02:33.007951Z"},"trusted":true},"outputs":[],"source":["def apply_ocr_to_image(license_plate_image):    \n","    # Threshold the image\n","    _, img = cv2.threshold(license_plate_image, 120, 255, cv2.THRESH_BINARY)\n","\n","    # Convert OpenCV image format to PIL Image format for pytesseract\n","    pil_img = Image.fromarray(img)\n","\n","    # Use pytesseract to extract text from the image\n","    full_text = pytesseract.image_to_string(pil_img, config='--psm 6')\n","\n","    return full_text.strip()  # Removing any extra white spaces from the ends"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"step6\"></a>\n","# <p style=\"background-color:#10191f; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 6 | Display Penalized License Plates</p>\n","\n","‚¨ÜÔ∏è [Tabel of Contents](#contents_tabel)"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border-radius:10px; padding: 15px; background-color: #a3b8c7; font-size:115%; text-align:left\"> \n","    \n","The function, `draw_penalized_text`, is adeptly built to display, on the video frames, the license plates that have been penalized. This dynamic display ensures that each fined license plate is shown in the order of its identification. Whether the video feed is from offline recordings or real-time monitoring, the list of fined plates is dynamically updated on the car monitoring screen.\n","____\n","    \n","With this function, viewers can easily track and view penalized license plates in real-time on their car monitoring screens, making it an indispensable tool for any vehicle monitoring or traffic management system."]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-08-16T20:02:33.025564Z","iopub.status.busy":"2023-08-16T20:02:33.024949Z","iopub.status.idle":"2023-08-16T20:02:33.040784Z","shell.execute_reply":"2023-08-16T20:02:33.03973Z","shell.execute_reply.started":"2023-08-16T20:02:33.025531Z"},"trusted":true},"outputs":[],"source":["def draw_penalized_text(frame):\n","    # Set font, scale, thickness, and color\n","    font = cv2.FONT_HERSHEY_TRIPLEX\n","    font_scale = 1  \n","    font_thickness = 2\n","    color = (255, 255, 255)  # White color\n","    \n","    # Initial position for Y-coordinate\n","    y_pos = 180\n","    \n","    # Put title on the frame\n","    cv2.putText(frame, 'Fined license plates:', (25, y_pos), font, font_scale, color, font_thickness)\n","    \n","    # Update Y-coordinate position\n","    y_pos += 80\n","\n","    # Loop through all fined license plates\n","    for text in penalized_texts:\n","        # Add fined license plate text on the frame\n","        cv2.putText(frame, '->  '+text, (40, y_pos), font, font_scale, color, font_thickness)\n","        \n","        # Update Y-coordinate for next license plate\n","        y_pos += 60"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"step7\"></a>\n","# <p style=\"background-color:#10191f; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 7 | Log Fined License Plates into MySQL</p>\n","\n","‚¨ÜÔ∏è [Tabel of Contents](#contents_tabel)"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border-radius:10px; padding: 15px; background-color: #a3b8c7; font-size:115%; text-align:left\"> \n","    \n","In this section. I am going to provide a set of functions working hand in hand to integrate with a __MySQL__ database, ensuring that all fined license plates are effectively recorded. These functions offer the ability to create, update, view, and clear license plate data as needed. Let's see a comprehensive breakdown of the functions:  \n","____\n","    \n","These functions collectively enable efficient and streamlined management of license plate violations, ensuring data accuracy and ease of access. Given the optional nature of some functions, developers can choose to deploy only those they find essential, depending on the application's needs."]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border-radius:10px; padding: 15px; background-color: #a3b8c7; font-size:115%; text-align:left\"> \n","    \n","__1. Database and Table Initialization ( `create_database_and_table` ):__ \n","- Establishes a connection to __MySQL__ with the provided credentials.\n","- Creates a new database if it doesn't exist, then selects it for further operations.\n","- Constructs a table named `license_plates` that holds records of each license plate along with their respective violation counts.\n","- It's essential to note that this function may be optional once a database is set up, as there's no need to recreate the structure repeatedly.\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-08-16T20:02:33.043344Z","iopub.status.busy":"2023-08-16T20:02:33.042315Z","iopub.status.idle":"2023-08-16T20:02:33.055191Z","shell.execute_reply":"2023-08-16T20:02:33.054125Z","shell.execute_reply.started":"2023-08-16T20:02:33.04331Z"},"trusted":true},"outputs":[],"source":["def create_database_and_table(host, user, password, database):\n","    try:\n","        # Create a connection\n","        connection = mysql.connector.connect(\n","            host = host,\n","            user = user,\n","            password = password\n","        )\n","        \n","        if connection.is_connected():\n","            # Create a new database cursor\n","            cursor = connection.cursor()\n","\n","            # Create a new database using the provided name\n","            cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {database}\")\n","            print(f\"Database {database} created successfully!\")\n","\n","            # Use the newly created database\n","            cursor.execute(f\"USE {database}\")\n","\n","            # Create a new table\n","            cursor.execute(\"\"\"\n","                CREATE TABLE IF NOT EXISTS license_plates (\n","                    id INT AUTO_INCREMENT PRIMARY KEY,\n","                    plate_number VARCHAR(255) NOT NULL UNIQUE,\n","                    violation_count INT DEFAULT 1\n","                )\n","            \"\"\")\n","            print(\"Table created successfully!\")\n","\n","            cursor.close()\n","\n","    except Error as e:\n","        print(\"Error while connecting to MySQL\", e)\n","\n","    finally:\n","        if connection.is_connected():\n","            connection.close()"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border-radius:10px; padding: 15px; background-color: #a3b8c7; font-size:115%; text-align:left\"> \n","    \n","__2. Recording Violations: ( `update_database_with_violation` ):__\n","- Connects to the specified MySQL database.\n","- Checks if a particular license plate already exists in the database.\n","- If the license plate exists, its violation count is incremented. If it doesn't, a new record for the license plate is added with a default violation count of 1."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-08-16T20:02:33.056952Z","iopub.status.busy":"2023-08-16T20:02:33.056638Z","iopub.status.idle":"2023-08-16T20:02:33.072025Z","shell.execute_reply":"2023-08-16T20:02:33.071131Z","shell.execute_reply.started":"2023-08-16T20:02:33.056925Z"},"trusted":true},"outputs":[],"source":["def update_database_with_violation(plate_number, host, user, password, database):\n","    try:\n","        connection = mysql.connector.connect(\n","            host = host,\n","            user = user,\n","            password = password,\n","            database = database\n","        )\n","        \n","        if connection.is_connected():\n","            cursor = connection.cursor()\n","\n","            # Check if the license plate already exists in the table\n","            cursor.execute(f\"SELECT violation_count FROM license_plates WHERE plate_number='{plate_number}'\")\n","            result = cursor.fetchone()\n","            \n","            if result:\n","                # Increment violation_count by 1 if plate_number already exists\n","                cursor.execute(f\"UPDATE license_plates SET violation_count=violation_count+1 WHERE plate_number='{plate_number}'\")\n","            else:\n","                # Insert a new record if plate_number doesn't exist\n","                cursor.execute(f\"INSERT INTO license_plates (plate_number) VALUES ('{plate_number}')\")\n","            \n","            connection.commit()\n","            cursor.close()\n","\n","    except Error as e:\n","        print(\"Error while connecting to MySQL\", e)\n","\n","    finally:\n","        if connection.is_connected():\n","            connection.close()"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border-radius:10px; padding: 15px; background-color: #a3b8c7; font-size:115%; text-align:left\"> \n","\n","__3. Viewing All Violations: ( `print_all_violations` ):__\n","- Fetches and displays all the recorded license plate violations, ordered by the number of violations.\n","- This function serves as an optional utility for users/admins who wish to view a snapshot of all violations. While it might not be necessary for all use cases, it provides a quick glance at the data."]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-08-16T20:02:33.074058Z","iopub.status.busy":"2023-08-16T20:02:33.07349Z","iopub.status.idle":"2023-08-16T20:02:33.089659Z","shell.execute_reply":"2023-08-16T20:02:33.088538Z","shell.execute_reply.started":"2023-08-16T20:02:33.074028Z"},"trusted":true},"outputs":[],"source":["def print_all_violations(host, user, password, database):\n","    try:\n","        connection = mysql.connector.connect(\n","            host = host,\n","            user = user,\n","            password = password,\n","            database = database\n","        )\n","        \n","        if connection.is_connected():\n","            cursor = connection.cursor()\n","\n","            # Fetch all violations from the database\n","            cursor.execute(\"SELECT plate_number, violation_count FROM license_plates ORDER BY violation_count DESC\")\n","            result = cursor.fetchall()\n","            \n","            print(\"\\n\")\n","            print(\"-\"*66)\n","            print(\"\\nAll Registered Traffic Violations in the Database:\\n\")\n","            for record in result:\n","                print(f\"Plate Number: {record[0]}, Violations: {record[1]}\")\n","            \n","            cursor.close()\n","\n","    except Error as e:\n","        print(\"Error while connecting to MySQL\", e)\n","\n","    finally:\n","        if connection.is_connected():\n","            connection.close()"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border-radius:10px; padding: 15px; background-color: #a3b8c7; font-size:115%; text-align:left\"> \n","    \n","__4. Clearing Recorded Data ( `clear_license_plates` ):__\n","- Deletes all the records in the `license_plates` table, effectively resetting the database.\n","- This function is also optional and can be seen as a tool for data management or debugging purposes. Routine operations might not require its use."]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-08-16T20:02:33.091791Z","iopub.status.busy":"2023-08-16T20:02:33.091159Z","iopub.status.idle":"2023-08-16T20:02:33.106973Z","shell.execute_reply":"2023-08-16T20:02:33.105757Z","shell.execute_reply.started":"2023-08-16T20:02:33.091757Z"},"trusted":true},"outputs":[],"source":["def clear_license_plates(host, user, password, database):\n","    try:\n","        connection = mysql.connector.connect(\n","            host = host,\n","            user = user,\n","            password = password,\n","            database = database\n","        )\n","        \n","        if connection.is_connected():\n","            cursor = connection.cursor()\n","\n","            # Delete all records from the table\n","            cursor.execute(\"DELETE FROM license_plates\")\n","\n","            connection.commit()\n","            cursor.close()\n","\n","    except Error as e:\n","        print(\"Error while connecting to MySQL\", e)\n","\n","    finally:\n","        if connection.is_connected():\n","            connection.close()"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"step8\"></a>\n","# <p style=\"background-color:#10191f; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 8 | Traffic Violation Monitoring Execution</p>\n","\n","‚¨ÜÔ∏è [Tabel of Contents](#contents_tabel)"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border-radius:10px; padding: 15px; background-color: #a3b8c7; font-size:115%; text-align:left\"> \n","    \n","Finally, I am going to define the `main` function which encapsulates the whole process of detecting license plate violations in a video feed. The function operates on an offline video of traffic, identifies the license plate of vehicles crossing the line when the light is red, and then processes the violations. Here's a comprehensive breakdown of its operations:\n","\n","__1. Database Setup__: As the function begins, it ensures that the appropriate database and table for storing license plate violations are available.\n","\n","    \n","__2. Video Feed__: The function reads the offline video `traffic_video.mp4`, frame by frame, and processes each frame to detect any traffic violations.\n","\n","    \n","__3. Traffic Light Detection__: The color of a traffic light for the given frame is detected using the `detect_traffic_light_color` function.\n","\n","    \n","__4. White Line Detection__: The function calls upon the `LineDetector` class to pinpoint the white stop line on the road, highlighting it based on the detected traffic light color.\n","\n","    \n","__5. Violation Detection & Processing__: If the detected color is red, the program uses the `extract_license_plate` and `apply_ocr_to_image` functions to identify vehicles crossing the white line and then to extract and read their license plates. Due to potential low-quality images fed to the `apply_ocr_to_image` function, some license plate readings may be incorrect. To counteract this, plates are verified against a predefined format, ensuring they match the standard format of a car license plate in the video. Only those that match and haven't been previously logged are recorded as violations.\n","\n","    \n","__6. Database Update__: The detected and processed license plates are recorded in the database. If a plate had a previous violation, its count is incremented.\n","\n","    \n","__7. Display Updates__: The `draw_penalized_text` function is called, which displays license plates that have been penalized in order on the frame.\n","\n","    \n","__8. Termination__: Processing continues until the video feed concludes or until the user terminates with the __ESC__ key. The video is then released, and all GUI windows close.\n","\n","    \n","__9. Report Generation__: Finally, the function fetches and lists all violations from the database, providing an overview of all infringements during the video's duration.\n","____\n","    \n","With this approach, the `main` function offers a robust and comprehensive solution to monitor and record traffic violations from a video source, marking its significance in traffic law enforcement and analytics.\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-08-16T20:02:33.1091Z","iopub.status.busy":"2023-08-16T20:02:33.108485Z","iopub.status.idle":"2023-08-16T20:02:33.121756Z","shell.execute_reply":"2023-08-16T20:02:33.120888Z","shell.execute_reply.started":"2023-08-16T20:02:33.109055Z"},"trusted":true},"outputs":[],"source":["def main():\n","    # Ensure the database and table exist\n","    create_database_and_table(DB_HOST, DB_USER, DB_PASSWORD, DB_NAME)\n","\n","    # Clear the license plates from the previous run. (Comment out this line if desired!)\n","    clear_license_plates(DB_HOST, DB_USER, DB_PASSWORD, DB_NAME)\n","\n","    # Open the video file\n","    vid = cv2.VideoCapture('./traffic_video_modified.mp4')\n","    \n","    # Create detector object\n","    detector = LineDetector()\n","\n","    # Loop through each frame in the video\n","    while True:\n","        # Read frame\n","        ret, frame = vid.read()\n","        \n","        # Break if frame is not returned\n","        if not ret:\n","            break\n","\n","        # Assuming rect is the rectangle where the traffic light is located\n","        rect = (1700, 40, 100, 250) \n","        \n","        # Detect traffic light color\n","        frame, color = detect_traffic_light_color(frame, rect)\n","        \n","        # Detect white line\n","        frame, mask_line = detector.detect_white_line(frame, color)\n","        \n","        # Process the frame if the light is red\n","        if color == 'red':\n","            # Extract license plate\n","            frame, license_plate_images = extract_license_plate(frame, mask_line)\n","            \n","            # Process each detected license plate\n","            for license_plate_image in license_plate_images:\n","                # Apply OCR to the license plate image\n","                text = apply_ocr_to_image(license_plate_image)\n","                \n","                # Add the detected license plate to the list if it matches the pattern and is not already in the list\n","                if text is not None and re.match(\"^[A-Z]{2}\\s[0-9]{3,4}$\", text) and text not in penalized_texts:\n","                    penalized_texts.append(text)\n","                    print(f\"\\nFined license plate: {text}\")\n","\n","                    # Plot the license plate image\n","                    plt.figure()\n","                    plt.imshow(license_plate_image, cmap='gray')\n","                    plt.axis('off')\n","                    plt.show()\n","                    \n","                    # Update the database with the license plate violation\n","                    update_database_with_violation(text, DB_HOST, DB_USER, DB_PASSWORD, DB_NAME)\n","        \n","        # Draw the penalized text onto the frame if there is any\n","        if penalized_texts:\n","            draw_penalized_text(frame)\n","\n","        # Display the frame \n","        cv2.imshow('frame', frame)\n","\n","        # Break if ESC key is pressed (uncomment the following line when running on a local system with GUI support)\n","        if cv2.waitKey(1) == 27:\n","            break\n","\n","    # Release the video\n","    vid.release()\n","    \n","    # Close all OpenCV windows (uncomment the following line when running on a local system with GUI support)\n","    cv2.destroyAllWindows()\n","\n","    # Print all the violations from the database\n","    print_all_violations(DB_HOST, DB_USER, DB_PASSWORD, DB_NAME)"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border-radius:10px; padding: 15px; background-color: #a3b8c7; font-size:115%; text-align:left\"> \n"," \n","Before diving into the primary operations of our program, a few preparatory steps are crucial:\n","\n","* __Haar Cascade Initialization and Download__: At the heart of our license plate detection mechanism, we use a Haar cascade classifier. For the Kaggle environment, we first download our pre-trained model, `haarcascade_russian_plate_number.xml`, from the GitHub repository. This model, tailor-made for detecting license plates, is paramount for identifying license plates in our video frames. By initializing the Haar cascade object here, we ensure our program doesn't suffer repeated delays due to multiple initializations.\n","\n","    \n","* __Creation of List__: Following this, we initialize a list named `penalized_texts`. This list functions as a repository, capturing the texts of license plates involved in traffic violations. The global definition of this list ensures both the `main` function and the `draw_penalized_text` function can access and update its contents without a hitch.\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-08-16T20:02:33.125636Z","iopub.status.busy":"2023-08-16T20:02:33.125264Z","iopub.status.idle":"2023-08-16T20:02:33.547732Z","shell.execute_reply":"2023-08-16T20:02:33.546631Z","shell.execute_reply.started":"2023-08-16T20:02:33.125605Z"},"trusted":true},"outputs":[],"source":["%%capture\n","# Download the trained Haar Cascade from the GitHub repository\n","url = \"https://raw.githubusercontent.com/FarzadNekouee/Traffic-Violation-Detection/master/haarcascade_russian_plate_number.xml\"\n","response = requests.get(url)\n","\n","with open('haarcascade_russian_plate_number.xml', 'wb') as file:\n","    file.write(response.content)\n","\n","# Load the trained Haar Cascade\n","license_plate_cascade = cv2.CascadeClassifier('haarcascade_russian_plate_number.xml')\n","\n","# Create a list to store unique penalized license plate texts\n","penalized_texts = []"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-08-16T20:02:33.549833Z","iopub.status.busy":"2023-08-16T20:02:33.549383Z","iopub.status.idle":"2023-08-16T20:02:33.554793Z","shell.execute_reply":"2023-08-16T20:02:33.554003Z","shell.execute_reply.started":"2023-08-16T20:02:33.54979Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Database traffic_violations_db created successfully!\n","Table created successfully!\n"]},{"ename":"error","evalue":"OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1272: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)","Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     main()\n","Cell \u001b[1;32mIn[19], line 61\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m     draw_penalized_text(frame)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Display the frame \u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Break if ESC key is pressed (uncomment the following line when running on a local system with GUI support)\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m:\n","\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1272: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"]}],"source":["if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border-radius:10px; padding: 15px; background-color: #a3b8c7; font-size:115%; text-align:left\"> \n","    \n","<h2 align=\"left\"><font color=#10191f>üîî Instructions for Running the Code:</font></h2>\n","\n","1. **Local Execution:** \n","   - This notebook is set up to showcase the processing steps. To fully execute and view the results on your machine, download this notebook.\n","   - Ensure you have the necessary dependencies installed and a local MySQL database set up.\n","   - Replace the placeholders `your_username` and `your_password` in the database connection constants with your own database credentials, as indicated in the previous instruction note.\n","   - Uncomment the `if __name__ == \"__main__\":` block to allow execution of the main function.\n","\n","    \n","2. **Output Preview:** \n","   - In this notebook, immediately following this instruction section, we present a snapshot of the expected results, including detected license plates and logs. üëá\n","   - For a dynamic preview, check out the embedded YouTube video at the beginning of this notebook which showcases the full output.\n","\n","    \n","3. **Full Project on GitHub:** \n","   - If you're interested in diving deeper, exploring more features, or contributing, the full project repository is available on [GitHub](https://github.com/FarzadNekouee/Traffic-Violation-Detection). Click on the link to directly access the repo.\n","   - We encourage you to clone it and experiment locally.\n","   - Make sure to check the README in the GitHub repository for detailed instructions on setup and execution.\n","\n","\n","<h3 align=\"left\"><font color=#10191f>üí° Tip:</font></h3>\n","    \n","By running this project on your local machine, you can see real-time detections and database updates, giving you a comprehensive understanding of its functionality.\n"]},{"cell_type":"markdown","metadata":{},"source":["<h3 align=\"left\"><font color=#10191f>Results snapshot:</font></h3>"]},{"cell_type":"markdown","metadata":{},"source":["![Expected Detection Outcomes: A Snapshot](https://raw.githubusercontent.com/FarzadNekouee/Traffic-Violation-Detection/master/result_snapshot.png)\n"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"display: flex; align-items: center; justify-content: center; border-radius: 10px; padding: 20px; background-color: #a3b8c7; font-size: 120%; text-align: center\">\n","\n","<strong>üéØ Feel free to visit the project repository on <a href=\"https://github.com/FarzadNekouee/Traffic-Violation-Detection\">GitHub</a> üéØ</strong>\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<h2 align=\"left\"><font color=#10191f>Best Regards!</font></h2>"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":3575465,"sourceId":6225062,"sourceType":"datasetVersion"}],"dockerImageVersionId":30527,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":4}
